

（程序在我自己电脑的虚拟机中测试通过。20140115目前还没部署到服务器测试过）

(1)@@@@解析日志数据入库

1.1
/SquidLogParse项目
squidLogParse.properties中配置日志文件的具体路径
jdbc.properties中配置数据库信息

1.2
将/SquidLogParse项目打包为SquidLogParse.jar，主程序为SquidLogParseMainExe.java（此为解析日志数据入库）。
注意将程序所依赖的jar包一同打包。

1.3
部署至linux运行(所有路径为我虚拟机中linux测试的路径，部署至真是服务器，改为真实相应的额路径即可)
（如日志路径为为/home/squidLogParse/access.log.0 ）
（将SquidLogParse.jar拷贝至/home/squidLogParse/路径下）
（在/home/squidLogParse/路径下建立auto.sh脚本，内容如下）
auto.sh(服务器上的)
---------------------------------
#!/bin/bash
JAVA_HOME=/home/zhenghao/jdk/jdk1.7.0_55
#PATH=$JAVA_HOME/bin:$PATH
#CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
/home/zhenghao/jdk/jdk1.7.0_55/bin/java -Dfile.encoding=UTF-8 -jar /home/zhenghao/squidLogParse/SquidLogParse.jar
---------------------------------

1.4
定时运行（服务器上的  每个小时的第10分钟执行）
10 */1 * * * sh /home/zhenghao/squidLogParse/auto.sh >> /home/zhenghao/squidLogParse/autosh.log

1.5
保存退出即可


=============================================================================================
=============================================================================================


(2)@@@@从库数据中提取出有用信息UV，VV，状态码信息等。

2.1
将/SquidLogParse项目打包为SquidLogInfoStorage.jar，主程序为LogInfoSecondStorageExe.java（此为解析二次解析提取数据主程序）

2.2
其他步骤与SquidLogParse.jar的部署定时运行，一致。
（两个定时的sh可以写在一个文件，日志也可以记在同一个文件，设置一下即可）
=============================================================================================
=============================================================================================

(3)@@@@。squid_log_analyse数据一直在增加，所以定期清理一下。ClearDbTableInfoExe.java实现的效果是
今天运行 清掉昨天的数据。用crontab 指定每天定时执行，就可以 使得 表中的数据得到 定期清理。


3.1
将/SquidLogParse项目打包为ClearDbTableInfo.jar，主程序为ClearDbTableInfoExe.java（此为解析给数据表定期清理数据 ）

3.2
将ClearDbTableInfo.jar部署至服务器定时运行即可 sh脚本同上不赘述
30 21 * * * ......... 
表示每天晚上9点30执行（ 执行时间可自行指定）
 



=============================================================================================
=============================================================================================

最终是三个jar包 在crontab中执行，一个为解析日志数据并入库。
另一个为对上一步取出的数据 进行加工处理得到uv，vv等信息。
还有一个定期清理squid_log_analyse表中数据。








